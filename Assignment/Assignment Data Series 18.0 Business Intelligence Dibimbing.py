# -*- coding: utf-8 -*-
"""Data Series 18.0 Business Intelligence Dibimbing

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GBfV2VMWevndYtffeDKiiEgX4VBDf16t

# IMPORT DATASET
crime-data-los-angeles.csv : This dataset reflects incidents of crime in the City of Los Angeles dating back to 2020. This data is transcribed from original crime reports that are typed on paper and therefore there may be some inaccuracies within the data.

the steps are as follows :
- import library
- read and load dataset
- display 5 last rows
"""

# import library
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from google.colab import drive
from google.colab import sheets
drive.mount('/content/drive')

# read and load dataset
df = pd.read_csv('/content/drive/MyDrive/Course/Datasets/crime-data-los-angeles.csv')
df.head()

# display 5 last rows
df.tail()

"""# EXPLORATORY DATASET
the steps are as follows :
- display info type data columns
- summary statistics dataset
- checking for missing values
- checking for duplicates
"""

# display info type data columns
df.info()

# summary statistics dataset
df.describe()

# checking for missing values
df.isnull().sum()

# checking for duplicates
duplicates = df.duplicated().sum()
print("\nNumber of duplicates in the dataset:")
print(duplicates)

"""# CLEANING DATASET
the steps are as follows :
- rename variable
- replace and columns missing values
- checking for missing values again
- dropping duplicates
- checking for duplicates again
"""

# rename variable
df = df.rename(columns={'DR_NO': 'number_id',
                        'Date Rptd': 'date_rptd',
                        'DATE OCC' : 'date_occ',
                        'TIME OCC' : 'time_occ',
                        'AREA': 'area_number',
                        'AREA NAME': 'area_name',
                        'Rpt Dist No' : 'rpt_dist_no',
                        'Part 1-2' : 'part_1/2',
                        'Crm Cd' : 'crime_cd',
                        'Crm Cd Desc': 'crime_cd_desc',
                        'Mocodes' : 'mocodes',
                        'Vict Age' : 'vict_age',
                        'Vict Sex': 'vict_sex',
                        'Vict Descent': 'vict_descent',
                        'Premis Cd' : 'premis_cd',
                        'Premis Desc' : 'premis_desc',
                        'Weapon Used Cd': 'weapon_used_cd',
                        'Weapon Desc': 'weapon_desc',
                        'Status' : 'status',
                        'Status Desc' : 'status_desc',
                        'Crm Cd 1' : 'crime_cd_1',
                        'Crm Cd 2' : 'crime_cd_2',
                        'Crm Cd 3' : 'crime_cd_3',
                        'Crm Cd 4' : 'crime_cd_4',
                        'LOCATION' : 'location',
                        'Cross Street': 'cross_street',
                        'LAT' : 'lat',
                        'LON' : 'lon'})
df.head()

# replace and columns missing values
df['mocodes'].fillna(df['mocodes'].mode()[0], inplace=True)
df['vict_sex'].fillna(df['vict_sex'].mode()[0], inplace=True)
df['vict_descent'].fillna(df['vict_descent'].mode()[0], inplace=True)
df['premis_cd'].fillna(df['premis_cd'].median(), inplace=True)
df['premis_desc'].fillna(df['premis_desc'].mode()[0], inplace=True)
df['weapon_used_cd'].fillna(df['weapon_used_cd'].median(), inplace=True)
df['weapon_desc'].fillna(df['weapon_desc'].mode()[0], inplace=True)
df['status'].fillna(df['status'].mode()[0], inplace=True)
df['cross_street'].fillna(df['cross_street'].mode()[0], inplace=True)
df.drop(columns=['crime_cd_1'], inplace=True)
df.drop(columns=['crime_cd_2'], inplace=True)
df.drop(columns=['crime_cd_3'], inplace=True)
df.drop(columns=['crime_cd_4'], inplace=True)

# checking for missing values again
missing_values_after = df.isnull().sum()
print("\nMissing values in the dataset after handling:")
print(missing_values_after)

# dropping duplicates
df.drop_duplicates(inplace=True)

# checking for duplicates again
duplicates_after = df.duplicated().sum()
print("\nNumber of duplicates in the dataset after removing duplicates:")
print(duplicates_after)

# displaying the first rows dataset
df.head()

# summary statistics dataset
print("\nSummary statistics of the dataset:")
df.describe()

# display info type data columns
df.info()

# load to csv
df.to_csv("crime-data-los-angeles-cleaning.csv", index=False)